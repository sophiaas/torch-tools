{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0161cf87-9394-449f-b70d-b20ec66923aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "852f27bf-c8d4-4b95-9ee9-16d28cc03bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral_networks.nn.models import ReLUNet\n",
    "from transform_datasets.patterns.synthetic import *\n",
    "from transform_datasets.transforms import *\n",
    "from transform_datasets.utils.wandb import load_or_create_dataset\n",
    "from torch_tools.trainer import Trainer\n",
    "from torch_tools.logger import WBLogger\n",
    "from torch_tools.config import Config\n",
    "from torch_tools.regularizer import Regularizer, MultiRegularizer\n",
    "from torch_tools.functional import l1_norm\n",
    "\n",
    "from torch_tools.data import TrainValLoader\n",
    "from pytorch_metric_learning import losses, distances\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch_tools.plotter import Plotter, MultiPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe2f70b3-8861-4c11-b5dd-83fe7fda9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PROJECT = \"dataset\"\n",
    "MODEL_PROJECT = \"bispectrum\"\n",
    "ENTITY = \"naturalcomputation\"\n",
    "DEVICE = \"cuda:0\"\n",
    "SEED = 0\n",
    "\n",
    "\"\"\"\n",
    "DATASET\n",
    "\"\"\"\n",
    "\n",
    "dataset_config = Config(\n",
    "    {\n",
    "        \"type\": HarmonicsS1,\n",
    "        \"params\": {\"dim\": 256, \"n_classes\": 10, \"seed\": 5},\n",
    "    }\n",
    ")\n",
    "\n",
    "transforms_config = {\n",
    "    \"0\": Config(\n",
    "        {\n",
    "            \"type\": CyclicTranslation1D,\n",
    "            \"params\": {\n",
    "                \"fraction_transforms\": 1.0,\n",
    "                \"sample_method\": \"linspace\",\n",
    "            },\n",
    "        }\n",
    "    ),\n",
    "    \"1\": Config(\n",
    "        {\n",
    "            \"type\": UniformNoise,\n",
    "            \"params\": {\"n_samples\": 1, \"magnitude\": 0.1},\n",
    "        }\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "tdataset_config = {\"dataset\": dataset_config, \"transforms\": transforms_config}\n",
    "\n",
    "dataset = load_or_create_dataset(tdataset_config, DATA_PROJECT, ENTITY)\n",
    "\n",
    "\"\"\"\n",
    "DATA_LOADER\n",
    "\"\"\"\n",
    "\n",
    "data_loader_config = Config(\n",
    "    {\n",
    "        \"type\": TrainValLoader,\n",
    "        \"params\": {\n",
    "            \"batch_size\": 32,\n",
    "            \"fraction_val\": 0.2,\n",
    "            \"num_workers\": 1,\n",
    "            \"seed\": SEED,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "data_loader = data_loader_config.build()\n",
    "data_loader.load(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d800d3b4-1680-4eec-a776-27fb09f0f745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">expert-sea-75</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/naturalcomputation/bispectrum\" target=\"_blank\">https://wandb.ai/naturalcomputation/bispectrum</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/naturalcomputation/bispectrum/runs/b5fducbi\" target=\"_blank\">https://wandb.ai/naturalcomputation/bispectrum/runs/b5fducbi</a><br/>\n",
       "                Run data is saved locally in <code>/home/christians/learning-lie-groups/torch-tools/examples/wandb/run-20210811_185744-b5fducbi</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "MODEL\n",
    "\"\"\"\n",
    "model_config = Config(\n",
    "    {\n",
    "        \"type\": ReLUNet,\n",
    "        \"params\": {\n",
    "            \"size_in\": dataset.dim,\n",
    "            \"hdim\": [256],\n",
    "            \"seed\": SEED,\n",
    "            \"device\": 'cuda:0'\n",
    "        },\n",
    "    }\n",
    ")\n",
    "model = model_config.build()\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIZER\n",
    "\"\"\"\n",
    "optimizer_config = Config({\"type\": Adam, \"params\": {\"lr\": 0.001}})\n",
    "# optimizer = optimizer_config.build()\n",
    "\n",
    "\n",
    "'''\n",
    "REGULARIZER\n",
    "'''\n",
    "regularizer_config1 = Config({'type': Regularizer, 'params': {'function': l1_norm, \n",
    "                                              'variables': ['out'],\n",
    "                                              'coefficient': 0.1\n",
    "                                             }\n",
    "                         })\n",
    "\n",
    "regularizer_config2 = Config({'type': Regularizer, 'params': {'function': l1_norm, \n",
    "                                              'variables': ['out'],\n",
    "                                              'coefficient': 1\n",
    "                                             }\n",
    "                         })\n",
    "\n",
    "multiregularizer_config = Config({'type': MultiRegularizer, 'params': {'regularizer_configs': [regularizer_config1, regularizer_config2]}})\n",
    "regularizer = multiregularizer_config.build()\n",
    "\n",
    "plotter_config1 = Config({'type': Plotter, 'params': {'function': gen_UVW_analysis_plots_1D, \n",
    "                                              'variables': ['model'],\n",
    "                                              'f_params': {'use_wandb': True}\n",
    "                                             }\n",
    "                         })\n",
    "\n",
    "plotter_config2 = Config({'type': Plotter, 'params': {'function': gen_avg_data_spectrum_plot_1D, \n",
    "                                              'variables': ['X'],\n",
    "                                              'f_params': {'use_wandb': True}\n",
    "                                             }\n",
    "                         })\n",
    "\n",
    "multiplotter_config = Config({'type': MultiPlotter, 'params': {'plotter_configs': [plotter_config1, plotter_config2]}})\n",
    "multiplotter = multiplotter_config.build()\n",
    "\n",
    "\"\"\"\n",
    "LOSS\n",
    "\"\"\"\n",
    "loss_config = Config(\n",
    "    {\n",
    "        \"type\": losses.ContrastiveLoss,\n",
    "        \"params\": {\n",
    "            \"pos_margin\": 0,\n",
    "            \"neg_margin\": 1,\n",
    "            \"distance\": distances.LpDistance(),\n",
    "        },\n",
    "    }\n",
    ")\n",
    "loss = loss_config.build()\n",
    "\n",
    "\"\"\"\n",
    "MASTER CONFIG\n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"dataset\": dataset_config,\n",
    "    \"model\": model_config,\n",
    "    \"optimizer\": optimizer_config,\n",
    "    \"loss\": loss_config,\n",
    "    \"data_loader\": data_loader_config,\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "LOGGING\n",
    "\"\"\"\n",
    "logging_config = Config(\n",
    "    {\n",
    "        \"type\": WBLogger,\n",
    "        \"params\": {\n",
    "            \"config\": config,\n",
    "            \"project\": MODEL_PROJECT,\n",
    "            \"entity\": ENTITY,\n",
    "            \"log_interval\": 10,\n",
    "            \"watch_interval\": 10 * len(data_loader.train),\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "logger = logging_config.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a14649-b213-4621-89d8-853af0e23e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAINER\n",
    "\"\"\"\n",
    "\n",
    "training_config = Config(\n",
    "    {\n",
    "        \"type\": Trainer,\n",
    "        \"params\": {\n",
    "            \"model\": model,\n",
    "            \"loss\": loss,\n",
    "            \"logger\": logger,\n",
    "            \"regularizer\": regularizer,\n",
    "            \"device\": DEVICE,\n",
    "            \"optimizer_config\": optimizer_config,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "trainer = training_config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9837cb4e-43b6-455b-972b-98426d4308ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ||  N Examples 0 || Train Total Loss 1220.19434 || Validation Total Loss 591.98187\n",
      "Epoch 1 ||  N Examples 2560 || Train Total Loss 411.13034 || Validation Total Loss 313.99680\n",
      "Epoch 2 ||  N Examples 5120 || Train Total Loss 311.36636 || Validation Total Loss 295.79642\n",
      "Epoch 3 ||  N Examples 7680 || Train Total Loss 289.18088 || Validation Total Loss 301.02658\n",
      "Epoch 4 ||  N Examples 10240 || Train Total Loss 289.71671 || Validation Total Loss 287.59137\n",
      "Epoch 5 ||  N Examples 12800 || Train Total Loss 283.72217 || Validation Total Loss 281.79419\n",
      "Epoch 6 ||  N Examples 15360 || Train Total Loss 276.84799 || Validation Total Loss 282.78635\n",
      "Epoch 7 ||  N Examples 17920 || Train Total Loss 269.70743 || Validation Total Loss 284.57587\n",
      "Epoch 8 ||  N Examples 20480 || Train Total Loss 268.85480 || Validation Total Loss 273.43777\n",
      "Epoch 9 ||  N Examples 23040 || Train Total Loss 265.91498 || Validation Total Loss 290.03711\n",
      "Epoch 10 ||  N Examples 25600 || Train Total Loss 257.00452 || Validation Total Loss 260.33890\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4240<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/christians/learning-lie-groups/torch-tools/examples/wandb/run-20210811_185744-b5fducbi/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/christians/learning-lie-groups/torch-tools/examples/wandb/run-20210811_185744-b5fducbi/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>1.19611</td></tr><tr><td>train_reg_loss</td><td>255.80835</td></tr><tr><td>train_total_loss</td><td>257.00452</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>n_examples</td><td>25600</td></tr><tr><td>_runtime</td><td>16</td></tr><tr><td>_timestamp</td><td>1628733480</td></tr><tr><td>_step</td><td>3</td></tr><tr><td>val_loss</td><td>1.18004</td></tr><tr><td>val_reg_loss</td><td>259.15884</td></tr><tr><td>val_total_loss</td><td>260.3389</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▁</td></tr><tr><td>train_reg_loss</td><td>█▁</td></tr><tr><td>train_total_loss</td><td>█▁</td></tr><tr><td>epoch</td><td>▁▁██</td></tr><tr><td>n_examples</td><td>▁▁██</td></tr><tr><td>_runtime</td><td>▁▂██</td></tr><tr><td>_timestamp</td><td>▁▂██</td></tr><tr><td>_step</td><td>▁▃▆█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_reg_loss</td><td>█▁</td></tr><tr><td>val_total_loss</td><td>█▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">expert-sea-75</strong>: <a href=\"https://wandb.ai/naturalcomputation/bispectrum/runs/b5fducbi\" target=\"_blank\">https://wandb.ai/naturalcomputation/bispectrum/runs/b5fducbi</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(data_loader, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a406e6-be22-466d-a84a-669e1d3a38b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Resuming run <strong style=\"color:#cdcd00\">expert-sea-75</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/naturalcomputation/bispectrum\" target=\"_blank\">https://wandb.ai/naturalcomputation/bispectrum</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/naturalcomputation/bispectrum/runs/b5fducbi\" target=\"_blank\">https://wandb.ai/naturalcomputation/bispectrum/runs/b5fducbi</a><br/>\n",
       "                Run data is saved locally in <code>/home/christians/learning-lie-groups/torch-tools/examples/wandb/run-20210811_185843-b5fducbi</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 ||  N Examples 28160 || Train Total Loss 248.80884 || Validation Total Loss 258.52383\n",
      "Epoch 11 ||  N Examples 30720 || Train Total Loss 243.10643 || Validation Total Loss 250.33142\n",
      "Epoch 12 ||  N Examples 33280 || Train Total Loss 241.74835 || Validation Total Loss 246.22932\n",
      "Epoch 13 ||  N Examples 35840 || Train Total Loss 235.39255 || Validation Total Loss 246.32678\n",
      "Epoch 14 ||  N Examples 38400 || Train Total Loss 227.36395 || Validation Total Loss 233.06372\n",
      "Epoch 15 ||  N Examples 40960 || Train Total Loss 220.58293 || Validation Total Loss 234.19165\n",
      "Epoch 16 ||  N Examples 43520 || Train Total Loss 214.53622 || Validation Total Loss 229.76579\n",
      "Epoch 17 ||  N Examples 46080 || Train Total Loss 211.59363 || Validation Total Loss 231.73355\n",
      "Epoch 18 ||  N Examples 48640 || Train Total Loss 204.53821 || Validation Total Loss 219.04488\n",
      "Epoch 19 ||  N Examples 51200 || Train Total Loss 202.05453 || Validation Total Loss 229.27260\n",
      "Epoch 20 ||  N Examples 53760 || Train Total Loss 197.64523 || Validation Total Loss 220.54938\n",
      "Epoch 21 ||  N Examples 56320 || Train Total Loss 192.30475 || Validation Total Loss 229.73874\n",
      "Epoch 22 ||  N Examples 58880 || Train Total Loss 188.11334 || Validation Total Loss 211.36836\n",
      "Epoch 23 ||  N Examples 61440 || Train Total Loss 183.89362 || Validation Total Loss 204.03421\n",
      "Epoch 24 ||  N Examples 64000 || Train Total Loss 178.49696 || Validation Total Loss 205.39403\n",
      "Epoch 25 ||  N Examples 66560 || Train Total Loss 180.04079 || Validation Total Loss 195.00137\n",
      "Epoch 26 ||  N Examples 69120 || Train Total Loss 169.90303 || Validation Total Loss 200.78651\n",
      "Epoch 27 ||  N Examples 71680 || Train Total Loss 167.95410 || Validation Total Loss 200.18272\n",
      "Epoch 28 ||  N Examples 74240 || Train Total Loss 163.21735 || Validation Total Loss 183.49344\n",
      "Epoch 29 ||  N Examples 76800 || Train Total Loss 158.55841 || Validation Total Loss 179.24286\n",
      "Epoch 30 ||  N Examples 79360 || Train Total Loss 159.00684 || Validation Total Loss 174.99139\n",
      "Epoch 31 ||  N Examples 81920 || Train Total Loss 152.54959 || Validation Total Loss 180.57945\n",
      "Epoch 32 ||  N Examples 84480 || Train Total Loss 153.63953 || Validation Total Loss 169.18080\n",
      "Epoch 33 ||  N Examples 87040 || Train Total Loss 142.57736 || Validation Total Loss 171.80617\n",
      "Epoch 34 ||  N Examples 89600 || Train Total Loss 141.24104 || Validation Total Loss 172.61342\n",
      "Epoch 35 ||  N Examples 92160 || Train Total Loss 137.20398 || Validation Total Loss 156.76509\n",
      "Epoch 36 ||  N Examples 94720 || Train Total Loss 130.05167 || Validation Total Loss 156.90346\n",
      "Epoch 37 ||  N Examples 97280 || Train Total Loss 134.03439 || Validation Total Loss 163.22090\n",
      "Epoch 38 ||  N Examples 99840 || Train Total Loss 131.93629 || Validation Total Loss 155.03539\n",
      "Epoch 39 ||  N Examples 102400 || Train Total Loss 121.75259 || Validation Total Loss 145.86958\n",
      "Epoch 40 ||  N Examples 104960 || Train Total Loss 124.17983 || Validation Total Loss 139.51906\n",
      "Epoch 41 ||  N Examples 107520 || Train Total Loss 116.48470 || Validation Total Loss 147.72353\n",
      "Epoch 42 ||  N Examples 110080 || Train Total Loss 116.68324 || Validation Total Loss 148.42844\n",
      "Epoch 43 ||  N Examples 112640 || Train Total Loss 112.88544 || Validation Total Loss 140.94795\n",
      "Epoch 44 ||  N Examples 115200 || Train Total Loss 108.04623 || Validation Total Loss 138.65839\n",
      "Epoch 45 ||  N Examples 117760 || Train Total Loss 107.76652 || Validation Total Loss 129.76146\n",
      "Epoch 46 ||  N Examples 120320 || Train Total Loss 105.81161 || Validation Total Loss 137.12419\n",
      "Epoch 47 ||  N Examples 122880 || Train Total Loss 104.73698 || Validation Total Loss 122.24960\n",
      "Epoch 48 ||  N Examples 125440 || Train Total Loss 101.88152 || Validation Total Loss 135.30603\n",
      "Epoch 49 ||  N Examples 128000 || Train Total Loss 99.24026 || Validation Total Loss 128.00046\n",
      "Epoch 50 ||  N Examples 130560 || Train Total Loss 97.34817 || Validation Total Loss 122.90178\n",
      "Epoch 51 ||  N Examples 133120 || Train Total Loss 97.71407 || Validation Total Loss 124.94725\n",
      "Epoch 52 ||  N Examples 135680 || Train Total Loss 93.77976 || Validation Total Loss 118.53044\n",
      "Epoch 53 ||  N Examples 138240 || Train Total Loss 93.69971 || Validation Total Loss 115.92629\n",
      "Epoch 54 ||  N Examples 140800 || Train Total Loss 91.87023 || Validation Total Loss 106.24236\n",
      "Epoch 55 ||  N Examples 143360 || Train Total Loss 90.29068 || Validation Total Loss 113.92975\n",
      "Epoch 56 ||  N Examples 145920 || Train Total Loss 81.62592 || Validation Total Loss 109.16573\n",
      "Epoch 57 ||  N Examples 148480 || Train Total Loss 81.80483 || Validation Total Loss 109.78645\n",
      "Epoch 58 ||  N Examples 151040 || Train Total Loss 83.24544 || Validation Total Loss 115.64961\n",
      "Epoch 59 ||  N Examples 153600 || Train Total Loss 77.90897 || Validation Total Loss 107.59763\n",
      "Epoch 60 ||  N Examples 156160 || Train Total Loss 78.95975 || Validation Total Loss 103.70000\n",
      "Epoch 61 ||  N Examples 158720 || Train Total Loss 78.43088 || Validation Total Loss 89.88696\n",
      "Epoch 62 ||  N Examples 161280 || Train Total Loss 76.76467 || Validation Total Loss 114.91542\n",
      "Epoch 63 ||  N Examples 163840 || Train Total Loss 76.79662 || Validation Total Loss 97.33463\n",
      "Epoch 64 ||  N Examples 166400 || Train Total Loss 70.94501 || Validation Total Loss 97.25081\n",
      "Epoch 65 ||  N Examples 168960 || Train Total Loss 71.84122 || Validation Total Loss 105.65403\n",
      "Epoch 66 ||  N Examples 171520 || Train Total Loss 83.24420 || Validation Total Loss 93.54642\n",
      "Epoch 67 ||  N Examples 174080 || Train Total Loss 71.02560 || Validation Total Loss 93.37201\n",
      "Epoch 68 ||  N Examples 176640 || Train Total Loss 67.71824 || Validation Total Loss 83.62292\n",
      "Epoch 69 ||  N Examples 179200 || Train Total Loss 69.51903 || Validation Total Loss 85.52013\n",
      "Epoch 70 ||  N Examples 181760 || Train Total Loss 64.30183 || Validation Total Loss 77.76387\n",
      "Epoch 71 ||  N Examples 184320 || Train Total Loss 66.40546 || Validation Total Loss 91.74698\n",
      "Epoch 72 ||  N Examples 186880 || Train Total Loss 68.74876 || Validation Total Loss 96.17008\n",
      "Epoch 73 ||  N Examples 189440 || Train Total Loss 64.85914 || Validation Total Loss 76.16615\n",
      "Epoch 74 ||  N Examples 192000 || Train Total Loss 65.86017 || Validation Total Loss 83.08674\n",
      "Epoch 75 ||  N Examples 194560 || Train Total Loss 66.66756 || Validation Total Loss 86.46976\n",
      "Epoch 76 ||  N Examples 197120 || Train Total Loss 71.75777 || Validation Total Loss 81.11657\n",
      "Epoch 77 ||  N Examples 199680 || Train Total Loss 67.81511 || Validation Total Loss 89.85881\n",
      "Epoch 78 ||  N Examples 202240 || Train Total Loss 64.54193 || Validation Total Loss 79.42189\n",
      "Epoch 79 ||  N Examples 204800 || Train Total Loss 63.39638 || Validation Total Loss 83.71091\n",
      "Epoch 80 ||  N Examples 207360 || Train Total Loss 66.00690 || Validation Total Loss 70.61800\n",
      "Epoch 81 ||  N Examples 209920 || Train Total Loss 54.03077 || Validation Total Loss 90.57881\n",
      "Epoch 82 ||  N Examples 212480 || Train Total Loss 61.10449 || Validation Total Loss 70.45720\n",
      "Epoch 83 ||  N Examples 215040 || Train Total Loss 65.61838 || Validation Total Loss 87.46981\n",
      "Epoch 84 ||  N Examples 217600 || Train Total Loss 58.46238 || Validation Total Loss 71.32973\n",
      "Epoch 85 ||  N Examples 220160 || Train Total Loss 64.99600 || Validation Total Loss 80.17164\n",
      "Epoch 86 ||  N Examples 222720 || Train Total Loss 55.88790 || Validation Total Loss 84.77801\n",
      "Epoch 87 ||  N Examples 225280 || Train Total Loss 53.84718 || Validation Total Loss 70.01488\n",
      "Epoch 88 ||  N Examples 227840 || Train Total Loss 55.80857 || Validation Total Loss 72.57286\n",
      "Epoch 89 ||  N Examples 230400 || Train Total Loss 52.09902 || Validation Total Loss 73.79333\n",
      "Epoch 90 ||  N Examples 232960 || Train Total Loss 54.32169 || Validation Total Loss 71.66177\n",
      "Epoch 91 ||  N Examples 235520 || Train Total Loss 53.88493 || Validation Total Loss 73.45863\n",
      "Epoch 92 ||  N Examples 238080 || Train Total Loss 54.41099 || Validation Total Loss 64.60320\n",
      "Epoch 93 ||  N Examples 240640 || Train Total Loss 56.24371 || Validation Total Loss 71.86033\n",
      "Epoch 94 ||  N Examples 243200 || Train Total Loss 59.78389 || Validation Total Loss 67.93863\n",
      "Epoch 95 ||  N Examples 245760 || Train Total Loss 56.36951 || Validation Total Loss 74.28713\n",
      "Epoch 96 ||  N Examples 248320 || Train Total Loss 54.77532 || Validation Total Loss 77.84399\n",
      "Epoch 97 ||  N Examples 250880 || Train Total Loss 59.28676 || Validation Total Loss 80.54628\n",
      "Epoch 98 ||  N Examples 253440 || Train Total Loss 51.56953 || Validation Total Loss 65.73199\n",
      "Epoch 99 ||  N Examples 256000 || Train Total Loss 50.52095 || Validation Total Loss 77.00724\n",
      "Epoch 100 ||  N Examples 258560 || Train Total Loss 53.66565 || Validation Total Loss 72.92525\n",
      "Epoch 101 ||  N Examples 261120 || Train Total Loss 64.26960 || Validation Total Loss 82.41505\n",
      "Epoch 102 ||  N Examples 263680 || Train Total Loss 54.44656 || Validation Total Loss 62.44347\n",
      "Epoch 103 ||  N Examples 266240 || Train Total Loss 52.49421 || Validation Total Loss 73.23906\n",
      "Epoch 104 ||  N Examples 268800 || Train Total Loss 57.99504 || Validation Total Loss 67.97865\n",
      "Epoch 105 ||  N Examples 271360 || Train Total Loss 56.52095 || Validation Total Loss 65.58823\n",
      "Epoch 106 ||  N Examples 273920 || Train Total Loss 49.60417 || Validation Total Loss 68.83665\n",
      "Epoch 107 ||  N Examples 276480 || Train Total Loss 56.75905 || Validation Total Loss 76.14317\n",
      "Epoch 108 ||  N Examples 279040 || Train Total Loss 54.80710 || Validation Total Loss 68.87935\n",
      "Epoch 109 ||  N Examples 281600 || Train Total Loss 52.80405 || Validation Total Loss 82.12849\n",
      "Epoch 110 ||  N Examples 284160 || Train Total Loss 54.56079 || Validation Total Loss 72.05654\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5006<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/christians/learning-lie-groups/torch-tools/examples/wandb/run-20210811_185843-b5fducbi/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/christians/learning-lie-groups/torch-tools/examples/wandb/run-20210811_185843-b5fducbi/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val_reg_loss</td><td>70.75697</td></tr><tr><td>val_loss</td><td>1.29956</td></tr><tr><td>n_examples</td><td>284160</td></tr><tr><td>train_reg_loss</td><td>53.26998</td></tr><tr><td>_step</td><td>25</td></tr><tr><td>epoch</td><td>110</td></tr><tr><td>_timestamp</td><td>1628733593</td></tr><tr><td>_runtime</td><td>87</td></tr><tr><td>val_total_loss</td><td>72.05654</td></tr><tr><td>train_loss</td><td>1.2908</td></tr><tr><td>train_total_loss</td><td>54.56079</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▁▂▃▅▆▇▇█▇▇▆</td></tr><tr><td>train_reg_loss</td><td>█▆▅▄▃▂▁▁▁▁▁</td></tr><tr><td>train_total_loss</td><td>█▆▅▄▃▂▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>n_examples</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>val_loss</td><td>▁▂▂▃▆▆▅█▇▇█</td></tr><tr><td>val_reg_loss</td><td>█▇▅▄▃▂▁▁▁▁▁</td></tr><tr><td>val_total_loss</td><td>█▇▅▄▃▂▁▁▁▁▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">expert-sea-75</strong>: <a href=\"https://wandb.ai/naturalcomputation/bispectrum/runs/b5fducbi\" target=\"_blank\">https://wandb.ai/naturalcomputation/bispectrum/runs/b5fducbi</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.resume(data_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819feeaa-11b4-4ad2-99c1-d4136b6a7242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d903c-0a2c-4f87-808c-012fbc1f9f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“torch18”",
   "language": "python",
   "name": "torch18"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
